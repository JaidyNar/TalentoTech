# -*- coding: utf-8 -*-
"""Ejercicio imputación Vinos

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hFZ-Tf90rB6A0NvlIkxRmzrh28HI_gIt

**type:**  tipo de vino, por ejemplo, vino blanco o vino tinto.

**fixed acidity:** La acidez fija se refiere a la cantidad de ácidos fijos en el vino, como el ácido tartárico.

**volatile acidity**: La acidez volátil se refiere a la cantidad de ácidos volátiles en el vino, que pueden afectar su aroma y sabor.

**citric acid: **El ácido cítrico es un ácido que se encuentra naturalmente en muchas frutas cítricas y se puede agregar al vino para ajustar su acidez.

**residual sugar:** El azúcar residual es la cantidad de azúcar que queda en el vino después de la fermentación.

**chlorides:** Los cloruros se refieren a la concentración de cloruros en el vino, lo cual puede afectar su sabor.

**free sulfur dioxide:** El dióxido de azufre libre es un compuesto que se utiliza como conservante en el vino.

**total sulfur dioxide:** El dióxido de azufre total es la suma del dióxido de azufre libre y el dióxido de azufre unido a otras moléculas en el vino.

**density:** La densidad del vino es una medida de su masa por unidad de volumen.

**pH:** El pH es una medida de la acidez o alcalinidad del vino.

**sulphates (sulfatos):** Los sulfatos son compuestos que pueden estar presentes en el vino y afectar su aroma y sabor.

**alcohol:** El contenido de alcohol en el vino, expresado típicamente como un porcentaje de volumen.

---


**quality:** La calidad del vino, que puede estar representada por una puntuación o una clasificación.
"""

!pip install plotly
import numpy as np
import pandas as pd

from matplotlib import pyplot as plt
import seaborn as sns
import plotly.graph_objs as go
import plotly.offline as py

from sklearn.impute import SimpleImputer
from sklearn.impute import KNNImputer
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
from sklearn import linear_model
from sklearn.preprocessing import MinMaxScaler

imputacion = "/content/drive/MyDrive/google colab/Wine_Quality.csv"
data = pd.read_csv(imputacion)

data.head()

print(data.shape)

data.describe([0.01, 0.05, 0.75, 0.90, 0.99]).T

data.info()

#datos en cero
data.isnull().sum()

# Para las columnas que no pueden ser cero, se reemplaza por NAN, con eso se elimina el sesgo que pueden introducir datos
data[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']] = data[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']].replace(0,np.NaN)
data.head()

# Creando un gráfico de datos faltantes para conocer cuantos valores incompletos hay en el conjunto de datos
def missing_plot(dataset, key) :
    null_feat = pd.DataFrame(len(dataset[key]) - dataset.isnull().sum(), columns = ['Count'])
    percentage_null = pd.DataFrame((len(dataset[key]) - (len(dataset[key]) - dataset.isnull().sum()))/len(dataset[key])*100, columns = ['Count'])
    percentage_null = percentage_null.round(2)

    trace = go.Bar(x = null_feat.index, y = null_feat['Count'] ,opacity = 0.8, text = percentage_null['Count'],  textposition = 'auto',marker=dict(color = '#7EC0EE',
            line=dict(color='#000000',width=1.5)))

    layout = dict(title = "Missing Values (count & %)")

    fig = dict(data = [trace], layout=layout)
    py.iplot(fig)

print(data.shape)

# Plotting
missing_plot(data, 'fixed acidity')

# revisando los datos faltantes en forma de tabla (missing columns)
def missing_percent(data):
        # Total missing values
        mis_val = data.isnull().sum()

        # Percentage of missing values
        mis_percent = 100 * data.isnull().sum() / len(data)

        # Make a table with the results
        mis_table = pd.concat([mis_val, mis_percent], axis=1)

        # Rename the columns
        mis_columns = mis_table.rename(
        columns = {0 : 'Missing Values', 1 : 'Percent of Total Values'})

        # Sort the table by percentage of missing descending
        mis_columns = mis_columns[
            mis_columns.iloc[:,1] != 0].sort_values(
        'Percent of Total Values', ascending=False).round(2)

        # Print some summary information
        print ("Your selected dataframe has " + str(data.shape[1]) + " columns.\n"
            "There are " + str(mis_columns.shape[0]) +
              " columns that have missing values.")

        # Return the dataframe with missing information
        return mis_columns

miss_cols_info = missing_percent(data)
miss_cols_info

# Las columnas con valores faltantes de más del 70% son eliminadas, se considera que en este caso los valores tienen tantas columnas faltantes que no se puede hacer nada con ellos.
 # se aplicarán diferentes operaciones de acuerdo a las proporciones de faltantes en el conjunto de datos. Por ejemplo, se quieren eliminar las variables independientes que tengan más del 25% de los datos faltantes.

data_drop = data.copy()
data_drop.head()

# Eliminando columnas con mas del 25% de datos faltantes
drop_cols = miss_cols_info[miss_cols_info['Percent of Total Values'] > 25]
drop_cols
# En este caso No se eliminan la columnas

col_names = drop_cols.index.tolist()
col_names
data_drop.drop(col_names, axis = 1, inplace=True)
data_drop.head()
print("Registros en el conjunto de datos original", data.shape)
print("Registros en el conjunto de datos", data_drop.shape)
# dataset con columnas eliminadas, en este caso se tiene el dataset sin esas dos características.

# si bien, una forma de trabajar con los datos es eliminar las columnas con faltantes (eliminar las características)
# sin embargo se podría optar por un enfoque diferente y es eliminar los registros que tengan NaN en esas columnas, es decir, no enfocarnos en las filas sino en las columnas
data_drop_rows = data.copy() # otra copia del dataset para evitar dañar los datos ya cargados en memoria
data_drop_rows.dropna(inplace=True) # eliminar NaNs en columnas con datos faltantes
print("Registros en el conjunto de datos original", data.shape)
print("Registros en el conjunto de datos", data_drop_rows.shape)
data_drop_rows.head()
# en este caso se mantienen las 13 columnas, pero se borran 183 filas

# Analyze visually with scatter plot
plt.style.use('seaborn')
fig = plt.Figure()
fig = data_drop_rows.plot(x="pH", y='citric acid', kind='scatter',
                    s = 10,
                    title='Dropping Rows', colorbar=False)

sns.histplot(
    data_drop_rows["citric acid"], kde=True,
    stat="density", kde_kws=dict(cut=3)
)
sns.set_style("darkgrid")

data_mean = data.copy()
round(data_mean['citric acid'].mean(), 2)

# Analyze visually with scatter plot
plt.style.use('seaborn')
fig = plt.Figure()
null_values = data['citric acid'].isnull()
fig = data_mean.plot(x="pH", y='citric acid', kind='scatter',
                     c=null_values, cmap='winter',s = 10,
                     title='Mean Imputation', colorbar=False)

sns.histplot(
    data_mean["citric acid"], kde=True,
    stat="density", kde_kws=dict(cut=3)
)
sns.set_style("darkgrid")

data_median = data.copy()
round(data_median['citric acid'].median(), 2)


# Imputacion con la mediana
median_imputer = SimpleImputer(missing_values = np.nan,
                        strategy ='median')
data_median['citric acid'] = median_imputer.fit_transform(
    data_median['citric acid'].values.reshape(-1,1))



# Analizar visualmente con diagrama de dispersión
plt.style.use('seaborn')
fig = plt.Figure()
null_values = data['citric acid'].isnull()
fig = data_median.plot(x="pH", y='citric acid', kind='scatter',
                     c=null_values, cmap='winter',s = 10,
                     title='Median Imputation', colorbar=False)

sns.histplot(
    data_median["citric acid"], kde=True,
    stat="density")
plt.grid()
sns.set_style("darkgrid")

"""Most of the imputation technique can cause bias. Simple imputation can result in an underestimation of standard errors. Simple imputed data for any statistic can lead to an underestimation of the standard error. As the number of missing data increases, simple imputation methods should be avoided.

2.2) Advanced imputation methods

One commonly adopted strategy for addressing missing data is to employ a predictive model to estimate the absent values. This technique entails developing a separate model for each input variable containing missing entries.

The default value of K is set to 5. Although there is no definitive method for determining the ideal value of K, a commonly used heuristic suggests that the optimal K is often the square root of the total number of samples in the dataset. Typically, an odd value is chosen for K to prevent ties in decision-making. To identify the most suitable K, an error plot or accuracy plot is commonly used.
"""

data_knn = data.copy()
data_knn = data_knn.filter(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality'], axis=1).copy()
data_knn.head()


scaler = MinMaxScaler(feature_range=(0, 1))
data_knn = pd.DataFrame(scaler.fit_transform(data_knn), columns = data_knn.columns)

# Define KNN imputer and fill missing values
knn_imputer = KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean')
data_knn_imputed = pd.DataFrame(knn_imputer.fit_transform(data_knn), columns=data_knn.columns)


data_knn_imputed.head()

original_data = scaler.inverse_transform(data_knn_imputed)
# Convert the original data to a DataFrame
data_original = pd.DataFrame(original_data, columns=data_knn.columns)


data_original.head()

fig = plt.Figure()
null_values = data['citric acid'].isnull()
fig = data_original.plot(x='pH', y='citric acid', kind='scatter',
                          c=null_values, cmap='winter', s = 15,
                          title='KNN Imputation', colorbar=False)

sns.histplot(
    data_original["citric acid"], kde=True,
    stat="density", kde_kws=dict(cut=3)
)
plt.title('KNN Imputation')

"""La imputación de K-vecinos más cercanos (KNN) tiende a generar costos computacionales más altos en comparación con los métodos de imputación simples. Sin embargo, es importante señalar que la imputación KNN sigue siendo eficaz para conjuntos de datos que no superan la escala de decenas de millones de registros. Sin embargo, como podemos ver en los diagramas de dispersión, knn parece haber completado los valores faltantes de una manera que no distorsiona una distribución normal.

MICE Imputation, abreviatura de 'Imputación múltiple por ecuación encadenada', es una técnica avanzada de imputación de datos faltantes que utiliza múltiples iteraciones de entrenamiento de modelos de aprendizaje automático para predecir los valores faltantes utilizando valores conocidos de otras características de los datos como predictores. ¿Cómo funciona el algoritmo MICE?

Aquí hay una intuición rápida (no el algoritmo exacto)

Básicamente, se toma la variable que contiene valores faltantes como respuesta 'Y' y otras variables como predictores 'X'.
Construya un modelo con filas donde no falte Y.
Luego predice las observaciones que faltan. Haga esto varias veces haciendo extracciones aleatorias de los datos y tomando la media de las predicciones.
"""

data = data.copy()
data_mice = data.filter(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality'], axis=1).copy()

# # Definir MICE Imputer y completar los valores faltantes
mice_imputer = IterativeImputer(estimator=linear_model.BayesianRidge(), n_nearest_features=None, imputation_order='ascending')
data_mice_imputed = pd.DataFrame(mice_imputer.fit_transform(data_mice), columns=data_mice.columns)

fig = plt.Figure()
null_values = data['citric acid'].isnull()
fig = data_mice_imputed.plot(x='pH', y='citric acid', kind='scatter',
                           c=null_values, cmap='winter', s = 15,
                           title='MICE Imputation', colorbar=False)

sns.histplot(
    data_mice_imputed["citric acid"], kde=True,
    stat="density", kde_kws=dict(cut=3)
)
plt.title('MICE Imputation')

# Comparacion de todos los métodos
drop_rows = pd.Series(data_drop_rows["citric acid"], name='drop_rows')
data_mean_ins = pd.Series(data_mean["citric acid"], name='Mean_Imp')
data_median_ins = pd.Series(data_median["citric acid"], name='Median_Imp')
data_knn_ins = pd.Series(data_original["citric acid"], name='KNN_Imp')
data_mice_ins = pd.Series(data_mice_imputed["citric acid"], name='MICE_Imp')

data_all = pd.concat([data_mean_ins,data_median_ins,data_knn_ins,data_mice_ins],axis=1)
data_all.head()

data_dropped = drop_rows.to_frame()
drop_desc = data_dropped.describe().loc[['mean', 'std']].T
drop_desc

drop_desc['std'][0]

data_desc = data_all.describe().loc[['mean', 'std']].T
data_desc

# barras de error
# Define etiquetas, posiciones, alturas de barras y alturas de barras de error
labels = ['Drop_Rows','Mean_Imp', 'Median_Imp', 'KNN_Imp', 'MICE_Imp']
x_pos = np.arange(len(labels))
CTEs = [drop_desc['mean'][0],data_desc["mean"][0], data_desc["mean"][1], data_desc["mean"][2], data_desc["mean"][3]]
error = [drop_desc['std'][0],data_desc["std"][0], data_desc["std"][1], data_desc["std"][2], data_desc["std"][3]]

# Build the plot
fig, ax = plt.subplots()
ax.bar(x_pos, CTEs,
       yerr=error,
       align='center',
       alpha=0.5,
       ecolor='black',
       capsize=10)
ax.set_ylabel('Insulin')
ax.set_xticks(x_pos)
ax.set_xticklabels(labels)
ax.set_title('Comparison of Methods')
ax.yaxis.grid(True)

# Save the figure and show
plt.tight_layout()
plt.savefig('bar_plot_with_error_bars.png')
plt.show()